{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choices\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1111\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    return pickle.load(open('df_down_sampled_alternative.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for splitting data into train/test set!\n",
    "\n",
    "def train_test_split(test_share, data):\n",
    "    \n",
    "    #Split data into initial train/test\n",
    "    \n",
    "    train_share = 1 - test_share    \n",
    "    train_size = int(len(data) * train_share)\n",
    "    train_set = data[0:train_size]\n",
    "    test_set = data[train_size:len(data)]    \n",
    "    \n",
    "    \n",
    "    return (train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_predictions(model, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = (predictions > 0.5).astype(int)\n",
    "    result = (predictions == y_test).astype(int)       \n",
    "    test_accuracy = result.mean()\n",
    "    \n",
    "    predictions = model.predict(X_train)\n",
    "    predictions = (predictions > 0.5).astype(int)\n",
    "    result = (predictions == y_train).astype(int)\n",
    "    train_accuracy = result.mean()\n",
    "    \n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contruct_outcome_vector(df, resp_cols):\n",
    "    \n",
    "    y = np.stack([(df[c] > 0).astype('int') for c in resp_cols]).T\n",
    "    \n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_data(df):\n",
    "    \n",
    "    df = df.loc[:,df.columns.str.contains('feature')]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load downsample frame! Zero-weight observations and data < 86 have already been removed!\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in df.columns if \"feature\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(test_share = 0.3, data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = contruct_outcome_vector(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = construct_input_data(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = contruct_outcome_vector(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = construct_input_data(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct NN-model!\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(150, input_dim = X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "220/220 [==============================] - 15s 65ms/step - loss: 0.7035 - auc: 0.5089\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 15s 68ms/step - loss: 0.6908 - auc: 0.5355\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 15s 70ms/step - loss: 0.6899 - auc: 0.5414\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 16s 74ms/step - loss: 0.6894 - auc: 0.5444\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 21s 94ms/step - loss: 0.6889 - auc: 0.5471\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 21s 96ms/step - loss: 0.6887 - auc: 0.5480\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 20s 93ms/step - loss: 0.6881 - auc: 0.5511 1s - loss: 0\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 19s 87ms/step - loss: 0.6878 - auc: 0.5511\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 21s 93ms/step - loss: 0.6877 - auc: 0.5518\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 21s 96ms/step - loss: 0.6873 - auc: 0.5538\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 21s 93ms/step - loss: 0.6869 - auc: 0.5555\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 20s 90ms/step - loss: 0.6866 - auc: 0.5558\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 23s 103ms/step - loss: 0.6864 - auc: 0.5565\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 21s 95ms/step - loss: 0.6861 - auc: 0.5576 8s - los - ETA: 2s \n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 19s 84ms/step - loss: 0.6857 - auc: 0.5588\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 22s 99ms/step - loss: 0.6855 - auc: 0.5593\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 23s 103ms/step - loss: 0.6851 - auc: 0.5604\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 23s 105ms/step - loss: 0.6849 - auc: 0.5611\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 22s 101ms/step - loss: 0.6847 - auc: 0.5619\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 23s 105ms/step - loss: 0.6844 - auc: 0.5626\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 22s 98ms/step - loss: 0.6841 - auc: 0.5635\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 29s 134ms/step - loss: 0.6839 - auc: 0.5643\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 18s 82ms/step - loss: 0.6837 - auc: 0.5647\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 17s 76ms/step - loss: 0.6835 - auc: 0.5654\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 22s 98ms/step - loss: 0.6832 - auc: 0.5662\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 23s 104ms/step - loss: 0.6831 - auc: 0.56652s\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 20s 91ms/step - loss: 0.6830 - auc: 0.5665\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 24s 111ms/step - loss: 0.6828 - auc: 0.5669\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 21s 98ms/step - loss: 0.6825 - auc: 0.5677\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 23s 106ms/step - loss: 0.6824 - auc: 0.5682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19cdc30f438>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 30, batch_size = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy, test_accuracy = score_predictions(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy on train-set: 0.5523. Accuracy on test-set: 0.5319\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuarcy on train-set: {}. Accuracy on test-set: {}\".format(np.round(train_accuracy,4), np.round(test_accuracy,4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "kaggle_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
