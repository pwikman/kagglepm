{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import choices\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for splitting data into train/test set!\n",
    "\n",
    "def train_test_split(test_share, data):\n",
    "    \n",
    "    #Split data into initial train/test\n",
    "    \n",
    "    train_share = 1 - test_share    \n",
    "    train_size = int(len(data) * train_share)\n",
    "    train_set = data[0:train_size]\n",
    "    test_set = data[train_size:len(data)]    \n",
    "    \n",
    "    \n",
    "    return (train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(\n",
    "    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n",
    "    for i in range(len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(num_labels)(x)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1111\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "train = pickle.load(open('df_down_sampled.p','rb'))\n",
    "#train = train.query('date > 85').reset_index(drop = True) \n",
    "train = train[train['weight'] != 0]\n",
    "\n",
    "train.fillna(train.mean(),inplace=True)\n",
    "\n",
    "train['action'] = ((train['resp'].values) > 0).astype(int)\n",
    "\n",
    "train_set, test_set = train_test_split(test_share = 0.3, data = train)\n",
    "\n",
    "features = [c for c in train.columns if \"feature\" in c]\n",
    "\n",
    "f_mean = np.mean(train_set[features[1:]].values,axis=0)\n",
    "\n",
    "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n",
    "\n",
    "X_train = train_set.loc[:, train_set.columns.str.contains('feature')]\n",
    "\n",
    "X_test = test_set.loc[:, test_set.columns.str.contains('feature')]\n",
    "\n",
    "y_train = np.stack([(train_set[c] > 0).astype('int') for c in resp_cols]).T\n",
    "\n",
    "y_test = np.stack([(test_set[c] > 0).astype('int') for c in resp_cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "hidden_units = [150, 150, 150]\n",
    "dropout_rates = [0.2, 0.2, 0.2, 0.2]\n",
    "label_smoothing = 1e-2\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = create_mlp(\n",
    "    len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "    )\n",
    "\n",
    "clf.fit(X_train, y_train, epochs=200, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)[:,1]\n",
    "\n",
    "train_roc = roc_auc_score(y_train, y_pred_train.reshape(-1, 1))\n",
    "\n",
    "y_pred_test = clf.predict(X_test)[:,1]\n",
    "\n",
    "test_roc = roc_auc_score(y_test, y_pred_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc: 0.6283306777850155, test roc: 0.5770965102540939\n"
     ]
    }
   ],
   "source": [
    "print(\"Train roc: {}, test roc: {}\".format(train_roc, test_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append(clf)\n",
    "\n",
    "th = 0.5000\n",
    "\n",
    "\n",
    "f = np.median\n",
    "models = models[-3:]\n",
    "import janestreet\n",
    "env = janestreet.make_env()\n",
    "for (test_df, pred_df) in tqdm(env.iter_test()):\n",
    "    if test_df['weight'].item() > 0:\n",
    "        x_tt = test_df.loc[:, features].values\n",
    "        if np.isnan(x_tt[:, 1:].sum()):\n",
    "            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n",
    "        pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\n",
    "        pred = f(pred)\n",
    "        pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n",
    "    else:\n",
    "        pred_df.action = 0\n",
    "    env.predict(pred_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
