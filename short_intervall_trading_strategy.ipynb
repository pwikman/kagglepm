{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import choices\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for loading data!\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    df = pickle.load(open('df_down_sampled.p','rb'))\n",
    "    df = df.drop(['resp_1', 'resp_2','resp_3','resp_4'], axis = 1)\n",
    "    df = df.sort_values(by = 'ts_id')\n",
    "    df['y'] = 0\n",
    "    mask = df.resp > 0\n",
    "    df.loc[mask,'y'] = 1    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for splitting data into train/test set!\n",
    "\n",
    "def train_test_split(test_share, data):\n",
    "    \n",
    "    #Split data into initial train/test\n",
    "    \n",
    "    train_share = 1 - test_share    \n",
    "    train_size = int(len(data) * train_share)\n",
    "    train_set = data[0:train_size]\n",
    "    test_set = data[train_size:len(data)]    \n",
    "    \n",
    "    \n",
    "    return (train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    \n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe is {start_memory} MB\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != 'object':\n",
    "           \n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                \n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:                    \n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                \n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                \n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                \n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    end_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\n",
    "    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_set(df):\n",
    "    \n",
    "    y = df.y\n",
    "    X = df.drop(['date','weight','y','ts_id', 'resp'], axis = 1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_most_recent_observations(df, n):\n",
    "    \n",
    "    \"\"\"Function takes as input a dataframe df, and returns the n most recent observations!\"\"\"\n",
    "    \n",
    "    cut_off = len(df) - n\n",
    "    \n",
    "    return df[cut_off:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, model):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_train_set_prediction(X_train, y_train, model):\n",
    "    \n",
    "    y_pred_train = model.predict_proba(X_train)[:,1]\n",
    "    train_roc = roc_auc_score(y_train, y_pred_train)\n",
    "    \n",
    "    return train_roc        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test_set(df):\n",
    "    \n",
    "    test_df = df.drop(['date','weight','ts_id', 'resp'], axis = 1)\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_test_set_prediction(test_df, model):    \n",
    "    \n",
    "    y_pred_test = model.predict_proba(test_df.drop('y', axis = 1))[:,1]\n",
    "    test_roc = roc_auc_score(test_df.y, y_pred_test)\n",
    "    \n",
    "    return test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_test_strategy(df, n, model):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function for back-testing trading-strategy. Takes as input the dataset (df) hyperparameter n, a model and a dictionary\n",
    "    for the model hyper-parameters. Df corresponds to the dataset for which we want to evaluate the trading-strategy. The\n",
    "    hyperparameter n corresponds to the number of new datapoints that we need to go through prior to using the (n) most\n",
    "    recent data-points to retrain the model.        \n",
    "    \"\"\"\n",
    "\n",
    "    train_set_predictions = []   \n",
    "    train_set_true = []\n",
    "    \n",
    "    test_set_predictions = []\n",
    "    test_set_true = []\n",
    "    \n",
    "    number_of_steps = int(len(df)/n)\n",
    "    print(\"The strategy consists of {} steps.\".format(number_of_steps))\n",
    "    \n",
    "    for i in range(number_of_steps):\n",
    "    \n",
    "        print(i)\n",
    "    \n",
    "        #Generate markers for where training starts and stops!\n",
    "    \n",
    "        start = i*n\n",
    "        stop = (i + 1)*n\n",
    "\n",
    "        #Split data into train/test set!\n",
    "    \n",
    "        train_df = df[start:stop]\n",
    "        \n",
    "        try:\n",
    "    \n",
    "            test_df = df[stop:(stop + n)]\n",
    "        \n",
    "        except:\n",
    "        \n",
    "            test_df = df[stop:]\n",
    "            \n",
    "        if len(test_df) == 0:\n",
    "            \n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            pass\n",
    "    \n",
    "        #Train model and collect train roc!\n",
    "    \n",
    "        X_train, y_train = generate_train_set(train_df)\n",
    "        model = train_model(X_train, y_train, model)\n",
    "        y_pred_train = model.predict_proba(X_train)[:,1]\n",
    "        train_set_predictions = train_set_predictions + y_pred_train.tolist()\n",
    "        train_set_true = train_set_true + y_train.tolist()\n",
    "        \n",
    "        #Predict on test set and collect test-roc!\n",
    "    \n",
    "        test_df = transform_test_set(test_df)\n",
    "        y_pred_test = model.predict_proba(test_df.drop('y', axis = 1))[:,1]\n",
    "        test_set_predictions = test_set_predictions + y_pred_test.tolist() \n",
    "        test_set_true = test_set_true + test_df.y.tolist()\n",
    "    \n",
    "    \n",
    "    train_set_predictions = np.array(train_set_predictions)\n",
    "    train_set_true = np.array(train_set_true)\n",
    "    \n",
    "    test_set_predictions = np.array(test_set_predictions)\n",
    "    test_set_true = np.array(test_set_true)\n",
    "    \n",
    "    train_roc = roc_auc_score(train_set_true, train_set_predictions)\n",
    "    test_roc = roc_auc_score(test_set_true, test_set_predictions)     \n",
    "    \n",
    "    return train_roc, test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_strategy(df, n, model):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function takes as input a dataframe df, model and a list (n) of strategy-hyperparameters \n",
    "    to test.\n",
    "    \n",
    "    Returns a dictionary with parameter values and the associated train/test roc:s.    \n",
    "    \"\"\"\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    for x in n:    \n",
    "        \n",
    "        train_roc, test_roc = back_test_strategy(df = df, n = x, model = model)\n",
    "        result_dict[x] = (train_roc, test_roc)\n",
    "        \n",
    "    return result_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_strategy_on_test_set(train_df, test_df, n, model):\n",
    "    \n",
    "    train_df = train_df.tail(n)\n",
    "    df = pd.concat([train_df, test_df], axis = 0)\n",
    "    \n",
    "    number_of_steps = int(len(df)/n)\n",
    "    print(\"The strategy consists of {} steps.\".format(number_of_steps))\n",
    "    \n",
    "    test_set_predictions = []\n",
    "    test_set_true = []\n",
    "    \n",
    "      \n",
    "    for i in range(number_of_steps):\n",
    "    \n",
    "        print(i)\n",
    "    \n",
    "        #Generate markers for where training starts and stops!\n",
    "    \n",
    "        start = i*n\n",
    "        stop = (i + 1)*n\n",
    "\n",
    "        #Split data into train/test set!\n",
    "    \n",
    "        train_df = df[start:stop]\n",
    "        \n",
    "        try:\n",
    "    \n",
    "            test_df = df[stop:(stop + n)]\n",
    "        \n",
    "        except:\n",
    "        \n",
    "            test_df = df[stop:]\n",
    "            \n",
    "        if len(test_df) == 0:\n",
    "            \n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            pass\n",
    "    \n",
    "        #Train model and collect train roc!\n",
    "    \n",
    "        X_train, y_train = generate_train_set(train_df)\n",
    "        model = train_model(X_train, y_train, model)\n",
    "\n",
    "        #Predict on test set and collect test-roc!\n",
    "    \n",
    "        test_df = transform_test_set(test_df)\n",
    "        y_pred_test = model.predict_proba(test_df.drop('y', axis = 1))[:,1]\n",
    "        test_set_predictions = test_set_predictions + y_pred_test.tolist() \n",
    "        test_set_true = test_set_true + test_df.y.tolist()\n",
    "        \n",
    "    \n",
    "    test_set_predictions = np.array(test_set_predictions)\n",
    "    test_set_true = np.array(test_set_true)\n",
    "    \n",
    "    test_roc = roc_auc_score(test_set_true, test_set_predictions)     \n",
    "    \n",
    "    return test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data!\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(test_share = 0.3, data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 369.0548095703125 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe after reduction 94.29893112182617 MB\n",
      "Reduced by 74.44852941176471 % \n"
     ]
    }
   ],
   "source": [
    "train_set = reduce_memory_usage(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 158.167236328125 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe after reduction 40.41405487060547 MB\n",
      "Reduced by 74.44852941176471 % \n"
     ]
    }
   ],
   "source": [
    "test_set = reduce_memory_usage(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = find_optimal_strategy(df = train_set, n = n, model = XGBClassifier(n_trees = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting at n = 3000, n_trees = 1 seems to increase performance. Test on hold out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The strategy consists of 51 steps.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5695695418421014"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_roc = implement_strategy_on_test_set(train_df = train_set, test_df = test_set, n = 3000, model = XGBClassifier(n_trees = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
