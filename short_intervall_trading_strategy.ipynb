{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import choices\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for loading data!\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    df = pickle.load(open('df_down_sampled.p','rb'))\n",
    "    df = df.drop(['resp_1', 'resp_2','resp_3','resp_4'], axis = 1)\n",
    "    df = df.sort_values(by = 'ts_id')\n",
    "    df['y'] = 0\n",
    "    mask = df.resp > 0\n",
    "    df.loc[mask,'y'] = 1    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for splitting data into train/test set!\n",
    "\n",
    "def train_test_split(test_share, data):\n",
    "    \n",
    "    #Split data into initial train/test\n",
    "    \n",
    "    train_share = 1 - test_share    \n",
    "    train_size = int(len(data) * train_share)\n",
    "    train_set = data[0:train_size]\n",
    "    test_set = data[train_size:len(data)]    \n",
    "    \n",
    "    \n",
    "    return (train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    \n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe is {start_memory} MB\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != 'object':\n",
    "           \n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                \n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:                    \n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                \n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                \n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                \n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    end_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\n",
    "    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_set(df):\n",
    "    \n",
    "    y = df.y\n",
    "    X = df.drop(['date','weight','y','ts_id', 'resp'], axis = 1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_most_recent_observations(df, n):\n",
    "    \n",
    "    \"\"\"Function takes as input a dataframe df, and returns the n most recent observations!\"\"\"\n",
    "    \n",
    "    cut_off = len(df) - n\n",
    "    \n",
    "    return df[cut_off:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xg_boost(X_train, y_train):\n",
    "    \n",
    "    model = XGBClassifier(max_depth=3)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_train_set_prediction(X_train, y_train, model):\n",
    "    \n",
    "    y_pred_train = model.predict_proba(X_train)[:,1]\n",
    "    train_roc = roc_auc_score(y_train, y_pred_train)\n",
    "    \n",
    "    return train_roc        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test_set(df):\n",
    "    \n",
    "    test_df = df.drop(['date','weight','ts_id', 'resp'], axis = 1)\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_test_set_prediction(test_df, model):    \n",
    "    \n",
    "    y_pred_test = model.predict_proba(test_df.drop('y', axis = 1))[:,1]\n",
    "    test_roc = roc_auc_score(test_df.y, y_pred_test)\n",
    "    \n",
    "    return test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_test_strategy(df, n, model, parameter_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function for back-testing trading-strategy. Takes as input the dataset (df) hyperparameter n, a model and a dictionary\n",
    "    for the model hyper-parameters. Df corresponds to the dataset for which we want to evaluate the trading-strategy. The\n",
    "    hyperparameter n corresponds to the number of new datapoints that we need to go through prio\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    train_roc = []\n",
    "    test_roc = []\n",
    "    \n",
    "    number_of_steps = int(len(df)/n)\n",
    "    print(\"The strategy consists of {} steps.\".format(number_of_steps))\n",
    "    \n",
    "    for i in range(number_of_steps):\n",
    "    \n",
    "        print(i)\n",
    "    \n",
    "        #Generate markers for where training starts and stops!\n",
    "    \n",
    "        start = i*n\n",
    "        stop = (i + 1)*n\n",
    "\n",
    "        #Split data into train/test set!\n",
    "    \n",
    "        train_df = df[start:stop]\n",
    "        \n",
    "        try:\n",
    "    \n",
    "            test_df = df[stop:(stop + n)]\n",
    "        \n",
    "        except:\n",
    "        \n",
    "            test_df = df[stop:]\n",
    "    \n",
    "        #Train model and collect train roc!\n",
    "    \n",
    "        X_train, y_train = generate_train_set(train_df)\n",
    "        model = train_xg_boost(X_train, y_train)\n",
    "        train_roc.append(score_train_set_prediction(X_train = X_train, y_train = y_train, model = model))\n",
    "        \n",
    "        #Predict on test set and collect test-roc!\n",
    "    \n",
    "        test_df = transform_test_set(test_df)\n",
    "        test_roc.append(score_test_set_prediction(test_df = test_df, model = model))\n",
    "        \n",
    "    return train_roc, test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_strategy(df, hyper_parameter_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function takes as input a dataframe df and a dictionary with parameter-values n and T that we want to test.\n",
    "    Note that the function assumes that the first value in the dictionary corresponds to T, and that the second\n",
    "    value corresponds to n.\n",
    "    \n",
    "    Returns a dictionary with parameter values and the associated train/test roc:s.    \n",
    "    \"\"\"\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    for x in list(product(*hyper_parameter_dict.values())):        \n",
    "        \n",
    "        train_roc, test_roc = back_test_strategy(df = df, T = x[0], n = x[1])\n",
    "        train_roc_avg = np.mean(train_roc)\n",
    "        test_roc_avg = np.mean(test_roc)\n",
    "        result_dict[x] = (train_roc_avg, test_roc_avg)\n",
    "        \n",
    "    return result_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data!\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(test_share = 0.3, data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 369.0548095703125 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe after reduction 94.29893112182617 MB\n",
      "Reduced by 74.44852941176471 % \n"
     ]
    }
   ],
   "source": [
    "train_set = reduce_memory_usage(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set[0:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameter_dict = {'n': [3000, 4000, 5000], 'T': [3100, 4100, 5100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The strategy consists of 9 steps.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "The strategy consists of 7 steps.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "The strategy consists of 5 steps.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "The strategy consists of 9 steps.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "The strategy consists of 7 steps.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "The strategy consists of 5 steps.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "The strategy consists of 9 steps.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "The strategy consists of 7 steps.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "The strategy consists of 5 steps.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "res_dict = find_optimal_strategy(df = train_set, hyper_parameter_dict = hyper_parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3000, 3100): (0.9865874053087853, 0.5562909756370533),\n",
       " (3000, 4100): (0.9718151808996913, 0.550088407877803),\n",
       " (3000, 5100): (0.9556202972947819, 0.5430961698959242),\n",
       " (4000, 3100): (0.9865874053087853, 0.5562909756370533),\n",
       " (4000, 4100): (0.9718151808996913, 0.550088407877803),\n",
       " (4000, 5100): (0.9556202972947819, 0.5430961698959242),\n",
       " (5000, 3100): (0.9865874053087853, 0.5562909756370533),\n",
       " (5000, 4100): (0.9718151808996913, 0.550088407877803),\n",
       " (5000, 5100): (0.9556202972947819, 0.5430961698959242)}"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
