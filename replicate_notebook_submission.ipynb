{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choices\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1111\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    return pickle.load(open('df_down_sampled_alternative.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for splitting data into train/test set!\n",
    "\n",
    "def train_test_split(test_share, data):\n",
    "    \n",
    "    #Split data into initial train/test\n",
    "    \n",
    "    train_share = 1 - test_share    \n",
    "    train_size = int(len(data) * train_share)\n",
    "    train_set = data[0:train_size]\n",
    "    test_set = data[train_size:len(data)]    \n",
    "    \n",
    "    \n",
    "    return (train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(\n",
    "    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = (num_columns,))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n",
    "    for i in range(len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(num_labels)(x)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    model.compile( \n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=tf.keras.metrics.AUC(name = \"AUC\"),\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load downsample frame! Zero-weight observations and data < 86 have already been removed!\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['action'] = ((df['resp'].values) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in df.columns if \"feature\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = np.mean(df[features[1:]].values,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(test_share = 0.3, data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.stack([(train_set[c] > 0).astype('int') for c in resp_cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.loc[:, train_set.columns.str.contains('feature')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.stack([(test_set[c] > 0).astype('int') for c in resp_cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_set.loc[:, test_set.columns.str.contains('feature')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0c1cdefd54ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "hidden_units = [150, 150, 150]\n",
    "dropout_rates = [0.2, 0.2, 0.2, 0.2]\n",
    "label_smoothing = 1e-2\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = create_mlp(\n",
    "    len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "220/220 [==============================] - 26s 108ms/step - loss: 0.7131 - AUC: 0.5144\n",
      "Epoch 2/200\n",
      "220/220 [==============================] - 24s 111ms/step - loss: 0.6922 - AUC: 0.5321\n",
      "Epoch 3/200\n",
      "220/220 [==============================] - 23s 106ms/step - loss: 0.6906 - AUC: 0.5377\n",
      "Epoch 4/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6900 - AUC: 0.5412\n",
      "Epoch 5/200\n",
      "220/220 [==============================] - 26s 120ms/step - loss: 0.6896 - AUC: 0.5439\n",
      "Epoch 6/200\n",
      "220/220 [==============================] - 26s 120ms/step - loss: 0.6894 - AUC: 0.5445\n",
      "Epoch 7/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6892 - AUC: 0.5458\n",
      "Epoch 8/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6889 - AUC: 0.5474\n",
      "Epoch 9/200\n",
      "220/220 [==============================] - 28s 129ms/step - loss: 0.6889 - AUC: 0.5475\n",
      "Epoch 10/200\n",
      "220/220 [==============================] - 32s 145ms/step - loss: 0.6886 - AUC: 0.5491\n",
      "Epoch 11/200\n",
      "220/220 [==============================] - 28s 126ms/step - loss: 0.6884 - AUC: 0.5498\n",
      "Epoch 12/200\n",
      "220/220 [==============================] - 27s 123ms/step - loss: 0.6884 - AUC: 0.5502\n",
      "Epoch 13/200\n",
      "220/220 [==============================] - 24s 111ms/step - loss: 0.6882 - AUC: 0.5508\n",
      "Epoch 14/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6881 - AUC: 0.5510\n",
      "Epoch 15/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6878 - AUC: 0.5525\n",
      "Epoch 16/200\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 0.6878 - AUC: 0.5525\n",
      "Epoch 17/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6876 - AUC: 0.5528\n",
      "Epoch 18/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6875 - AUC: 0.5533\n",
      "Epoch 19/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6874 - AUC: 0.5539\n",
      "Epoch 20/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6872 - AUC: 0.5548\n",
      "Epoch 21/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6870 - AUC: 0.5552\n",
      "Epoch 22/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6869 - AUC: 0.5559\n",
      "Epoch 23/200\n",
      "220/220 [==============================] - 27s 123ms/step - loss: 0.6869 - AUC: 0.5562\n",
      "Epoch 24/200\n",
      "220/220 [==============================] - 26s 120ms/step - loss: 0.6867 - AUC: 0.5565\n",
      "Epoch 25/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6867 - AUC: 0.5561\n",
      "Epoch 26/200\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 0.6864 - AUC: 0.5575\n",
      "Epoch 27/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6864 - AUC: 0.5573\n",
      "Epoch 28/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6862 - AUC: 0.5583\n",
      "Epoch 29/200\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 0.6860 - AUC: 0.5593\n",
      "Epoch 30/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6859 - AUC: 0.5596\n",
      "Epoch 31/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6861 - AUC: 0.5581\n",
      "Epoch 32/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6859 - AUC: 0.5587\n",
      "Epoch 33/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6858 - AUC: 0.5594\n",
      "Epoch 34/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6856 - AUC: 0.5602\n",
      "Epoch 35/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6857 - AUC: 0.5599\n",
      "Epoch 36/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6855 - AUC: 0.5605\n",
      "Epoch 37/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6856 - AUC: 0.5600\n",
      "Epoch 38/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6853 - AUC: 0.5610\n",
      "Epoch 39/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6853 - AUC: 0.5610\n",
      "Epoch 40/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6852 - AUC: 0.5613\n",
      "Epoch 41/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6851 - AUC: 0.5614\n",
      "Epoch 42/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6851 - AUC: 0.5613\n",
      "Epoch 43/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6848 - AUC: 0.5618\n",
      "Epoch 44/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6849 - AUC: 0.5623\n",
      "Epoch 45/200\n",
      "220/220 [==============================] - 27s 123ms/step - loss: 0.6847 - AUC: 0.5628\n",
      "Epoch 46/200\n",
      "220/220 [==============================] - 26s 120ms/step - loss: 0.6849 - AUC: 0.5613\n",
      "Epoch 47/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6848 - AUC: 0.5621\n",
      "Epoch 48/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6845 - AUC: 0.5633\n",
      "Epoch 49/200\n",
      "220/220 [==============================] - 27s 121ms/step - loss: 0.6846 - AUC: 0.5626\n",
      "Epoch 50/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6844 - AUC: 0.5633\n",
      "Epoch 51/200\n",
      "220/220 [==============================] - 25s 112ms/step - loss: 0.6843 - AUC: 0.5638\n",
      "Epoch 52/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6844 - AUC: 0.5632\n",
      "Epoch 53/200\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 0.6845 - AUC: 0.5627\n",
      "Epoch 54/200\n",
      "220/220 [==============================] - 27s 122ms/step - loss: 0.6842 - AUC: 0.5639\n",
      "Epoch 55/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6843 - AUC: 0.5636\n",
      "Epoch 56/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6843 - AUC: 0.5634\n",
      "Epoch 57/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6841 - AUC: 0.5647\n",
      "Epoch 58/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6841 - AUC: 0.5640\n",
      "Epoch 59/200\n",
      "220/220 [==============================] - 26s 120ms/step - loss: 0.6841 - AUC: 0.5639\n",
      "Epoch 60/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6839 - AUC: 0.5648\n",
      "Epoch 61/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6841 - AUC: 0.5640\n",
      "Epoch 62/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6839 - AUC: 0.5648\n",
      "Epoch 63/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6841 - AUC: 0.5643\n",
      "Epoch 64/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6839 - AUC: 0.5644\n",
      "Epoch 65/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6838 - AUC: 0.5650\n",
      "Epoch 66/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6837 - AUC: 0.5654\n",
      "Epoch 67/200\n",
      "220/220 [==============================] - 26s 120ms/step - loss: 0.6837 - AUC: 0.5651\n",
      "Epoch 68/200\n",
      "220/220 [==============================] - 27s 121ms/step - loss: 0.6837 - AUC: 0.5650\n",
      "Epoch 69/200\n",
      "220/220 [==============================] - 25s 112ms/step - loss: 0.6838 - AUC: 0.5649\n",
      "Epoch 70/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6836 - AUC: 0.5655\n",
      "Epoch 71/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6836 - AUC: 0.5657\n",
      "Epoch 72/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6835 - AUC: 0.5659\n",
      "Epoch 73/200\n",
      "220/220 [==============================] - 27s 122ms/step - loss: 0.6835 - AUC: 0.5654\n",
      "Epoch 74/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6833 - AUC: 0.5661\n",
      "Epoch 75/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6835 - AUC: 0.5659\n",
      "Epoch 76/200\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 0.6834 - AUC: 0.5664\n",
      "Epoch 77/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6832 - AUC: 0.5669\n",
      "Epoch 78/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6832 - AUC: 0.5663\n",
      "Epoch 79/200\n",
      "220/220 [==============================] - 27s 124ms/step - loss: 0.6832 - AUC: 0.5667\n",
      "Epoch 80/200\n",
      "220/220 [==============================] - 25s 112ms/step - loss: 0.6831 - AUC: 0.5675\n",
      "Epoch 81/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6831 - AUC: 0.5667\n",
      "Epoch 82/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6832 - AUC: 0.5663\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6831 - AUC: 0.5666\n",
      "Epoch 84/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6830 - AUC: 0.5673\n",
      "Epoch 85/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6831 - AUC: 0.5663\n",
      "Epoch 86/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6831 - AUC: 0.5667\n",
      "Epoch 87/200\n",
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6829 - AUC: 0.5677\n",
      "Epoch 88/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6830 - AUC: 0.5668\n",
      "Epoch 89/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6828 - AUC: 0.5678\n",
      "Epoch 90/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6829 - AUC: 0.5672\n",
      "Epoch 91/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6827 - AUC: 0.5673\n",
      "Epoch 92/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6830 - AUC: 0.5673\n",
      "Epoch 93/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6827 - AUC: 0.5682\n",
      "Epoch 94/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6828 - AUC: 0.5674\n",
      "Epoch 95/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6827 - AUC: 0.5679\n",
      "Epoch 96/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6827 - AUC: 0.5683\n",
      "Epoch 97/200\n",
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6826 - AUC: 0.5689\n",
      "Epoch 98/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6826 - AUC: 0.5682\n",
      "Epoch 99/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6828 - AUC: 0.5681\n",
      "Epoch 100/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6826 - AUC: 0.5686\n",
      "Epoch 101/200\n",
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6827 - AUC: 0.5677\n",
      "Epoch 102/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6827 - AUC: 0.5677\n",
      "Epoch 103/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6825 - AUC: 0.5684\n",
      "Epoch 104/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6825 - AUC: 0.5685\n",
      "Epoch 105/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6823 - AUC: 0.5688\n",
      "Epoch 106/200\n",
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6825 - AUC: 0.5684\n",
      "Epoch 107/200\n",
      "220/220 [==============================] - 27s 125ms/step - loss: 0.6825 - AUC: 0.5687\n",
      "Epoch 108/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6825 - AUC: 0.5681\n",
      "Epoch 109/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6824 - AUC: 0.5689\n",
      "Epoch 110/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6824 - AUC: 0.5694\n",
      "Epoch 111/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6823 - AUC: 0.5694\n",
      "Epoch 112/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6822 - AUC: 0.5695\n",
      "Epoch 113/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6822 - AUC: 0.5692\n",
      "Epoch 114/200\n",
      "220/220 [==============================] - 25s 112ms/step - loss: 0.6824 - AUC: 0.5693\n",
      "Epoch 115/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6822 - AUC: 0.5695\n",
      "Epoch 116/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6821 - AUC: 0.5699\n",
      "Epoch 117/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6822 - AUC: 0.5691\n",
      "Epoch 118/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6821 - AUC: 0.5701\n",
      "Epoch 119/200\n",
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6823 - AUC: 0.5691\n",
      "Epoch 120/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6820 - AUC: 0.5698\n",
      "Epoch 121/200\n",
      "220/220 [==============================] - 25s 112ms/step - loss: 0.6823 - AUC: 0.5690\n",
      "Epoch 122/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6820 - AUC: 0.5702\n",
      "Epoch 123/200\n",
      "220/220 [==============================] - 27s 122ms/step - loss: 0.6820 - AUC: 0.5700\n",
      "Epoch 124/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6819 - AUC: 0.5706\n",
      "Epoch 125/200\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 0.6820 - AUC: 0.5700\n",
      "Epoch 126/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6822 - AUC: 0.5697\n",
      "Epoch 127/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6820 - AUC: 0.5698\n",
      "Epoch 128/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6819 - AUC: 0.5703\n",
      "Epoch 129/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6817 - AUC: 0.5707\n",
      "Epoch 130/200\n",
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6820 - AUC: 0.5697\n",
      "Epoch 131/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6820 - AUC: 0.5695\n",
      "Epoch 132/200\n",
      "220/220 [==============================] - 27s 121ms/step - loss: 0.6821 - AUC: 0.5696\n",
      "Epoch 133/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6819 - AUC: 0.5701\n",
      "Epoch 134/200\n",
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6820 - AUC: 0.5697\n",
      "Epoch 135/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6822 - AUC: 0.5691\n",
      "Epoch 136/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6817 - AUC: 0.5710\n",
      "Epoch 137/200\n",
      "220/220 [==============================] - 26s 120ms/step - loss: 0.6818 - AUC: 0.5704\n",
      "Epoch 138/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6819 - AUC: 0.5702\n",
      "Epoch 139/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6817 - AUC: 0.5713\n",
      "Epoch 140/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6819 - AUC: 0.5702\n",
      "Epoch 141/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6817 - AUC: 0.5707\n",
      "Epoch 142/200\n",
      "220/220 [==============================] - 26s 120ms/step - loss: 0.6817 - AUC: 0.5707\n",
      "Epoch 143/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6819 - AUC: 0.5701\n",
      "Epoch 144/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6817 - AUC: 0.5705\n",
      "Epoch 145/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6814 - AUC: 0.5723\n",
      "Epoch 146/200\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 0.6817 - AUC: 0.5710\n",
      "Epoch 147/200\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 0.6816 - AUC: 0.5714\n",
      "Epoch 148/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6816 - AUC: 0.5706\n",
      "Epoch 149/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6817 - AUC: 0.5704\n",
      "Epoch 150/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6816 - AUC: 0.5709\n",
      "Epoch 151/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6814 - AUC: 0.5719\n",
      "Epoch 152/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6817 - AUC: 0.5709\n",
      "Epoch 153/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6815 - AUC: 0.5722\n",
      "Epoch 154/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6815 - AUC: 0.5712\n",
      "Epoch 155/200\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 0.6815 - AUC: 0.5718\n",
      "Epoch 156/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6815 - AUC: 0.5710\n",
      "Epoch 157/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6814 - AUC: 0.5712\n",
      "Epoch 158/200\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 0.6817 - AUC: 0.5712\n",
      "Epoch 159/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6816 - AUC: 0.5713\n",
      "Epoch 160/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6815 - AUC: 0.5714\n",
      "Epoch 161/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6814 - AUC: 0.5714\n",
      "Epoch 162/200\n",
      "220/220 [==============================] - 27s 123ms/step - loss: 0.6813 - AUC: 0.5718\n",
      "Epoch 163/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6813 - AUC: 0.5719\n",
      "Epoch 164/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6815 - AUC: 0.5713\n",
      "Epoch 165/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6814 - AUC: 0.5716\n",
      "Epoch 166/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6814 - AUC: 0.5716\n",
      "Epoch 167/200\n",
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6815 - AUC: 0.5715\n",
      "Epoch 168/200\n",
      "220/220 [==============================] - 27s 122ms/step - loss: 0.6812 - AUC: 0.5722\n",
      "Epoch 169/200\n",
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6813 - AUC: 0.5716\n",
      "Epoch 170/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6815 - AUC: 0.5714\n",
      "Epoch 171/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6813 - AUC: 0.5720\n",
      "Epoch 172/200\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 0.6813 - AUC: 0.5717\n",
      "Epoch 173/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6811 - AUC: 0.5724\n",
      "Epoch 174/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6812 - AUC: 0.5720\n",
      "Epoch 175/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6811 - AUC: 0.5731\n",
      "Epoch 176/200\n",
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6813 - AUC: 0.5717\n",
      "Epoch 177/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6813 - AUC: 0.5721\n",
      "Epoch 178/200\n",
      "220/220 [==============================] - 26s 118ms/step - loss: 0.6812 - AUC: 0.5725\n",
      "Epoch 179/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6815 - AUC: 0.5714\n",
      "Epoch 180/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6811 - AUC: 0.5725\n",
      "Epoch 181/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6811 - AUC: 0.5724\n",
      "Epoch 182/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6809 - AUC: 0.5730\n",
      "Epoch 183/200\n",
      "220/220 [==============================] - 26s 119ms/step - loss: 0.6811 - AUC: 0.5728\n",
      "Epoch 184/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6813 - AUC: 0.5722\n",
      "Epoch 185/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6811 - AUC: 0.5727\n",
      "Epoch 186/200\n",
      "220/220 [==============================] - 27s 122ms/step - loss: 0.6809 - AUC: 0.5727\n",
      "Epoch 187/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6810 - AUC: 0.5724\n",
      "Epoch 188/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6811 - AUC: 0.5724\n",
      "Epoch 189/200\n",
      "220/220 [==============================] - 25s 113ms/step - loss: 0.6812 - AUC: 0.5719\n",
      "Epoch 190/200\n",
      "220/220 [==============================] - 26s 116ms/step - loss: 0.6810 - AUC: 0.5729\n",
      "Epoch 191/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6810 - AUC: 0.5732\n",
      "Epoch 192/200\n",
      "220/220 [==============================] - 25s 114ms/step - loss: 0.6810 - AUC: 0.5729\n",
      "Epoch 193/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6810 - AUC: 0.5728\n",
      "Epoch 194/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6811 - AUC: 0.5727\n",
      "Epoch 195/200\n",
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6811 - AUC: 0.5724\n",
      "Epoch 196/200\n",
      "220/220 [==============================] - 25s 116ms/step - loss: 0.6811 - AUC: 0.5722\n",
      "Epoch 197/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6810 - AUC: 0.5730\n",
      "Epoch 198/200\n",
      "220/220 [==============================] - 27s 122ms/step - loss: 0.6810 - AUC: 0.5731\n",
      "Epoch 199/200\n",
      "220/220 [==============================] - 25s 115ms/step - loss: 0.6810 - AUC: 0.5724\n",
      "Epoch 200/200\n",
      "220/220 [==============================] - 26s 117ms/step - loss: 0.6810 - AUC: 0.5733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21e0c34f6a0>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, epochs = 200, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle weakref objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-60f09f0dbfff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tf_model.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle weakref objects"
     ]
    }
   ],
   "source": [
    "pickle.dump(clf, open('tf_model.csv','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append(clf)\n",
    "th = 0.5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = models[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (pred == y_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "kaggle_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
