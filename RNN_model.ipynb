{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import keras\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy import array\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pandas.plotting import lag_plot\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for loading data!\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    df = pickle.load(open('df_down_sampled.p','rb'))\n",
    "    df = df.drop(['resp_1', 'resp_2','resp_3','resp_4'], axis = 1)\n",
    "    df = df.sort_values(by = 'ts_id')\n",
    "    df['y'] = 0\n",
    "    mask = df.resp > 0\n",
    "    df.loc[mask,'y'] = 1    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for performing pca-transformation!\n",
    "\n",
    "def perform_pca_transformation(X_train, X_test, number_of_components):\n",
    "    \n",
    "    col_list = []\n",
    "\n",
    "    for x in range(number_of_components):\n",
    "        \n",
    "        col_list.append('pca_feature_' + str(x))\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    pca = PCA(n_components = number_of_components)\n",
    "    pca.fit(X_train_scaled)\n",
    "    \n",
    "    X_train_pca = pca.transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "    \n",
    "    X_train_pca = pd.DataFrame(data = X_train_pca, columns = col_list)\n",
    "    X_test_pca = pd.DataFrame(data = X_test_pca, columns = col_list)\n",
    "    \n",
    "    return (X_train_pca, X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for splitting data into train/test set!\n",
    "\n",
    "def train_test_split(test_share, data):\n",
    "    \n",
    "    #Split data into initial train/test\n",
    "    \n",
    "    train_share = 1 - test_share    \n",
    "    train_size = int(len(data) * train_share)\n",
    "    train_set = data[0:train_size]\n",
    "    test_set = data[train_size:len(data)]    \n",
    "    \n",
    "    \n",
    "    return (train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    \n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe is {start_memory} MB\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != 'object':\n",
    "           \n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                \n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:                    \n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                \n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                \n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                \n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    end_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\n",
    "    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data!\n",
    "\n",
    "df = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>ts_id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>532070</th>\n",
       "      <td>87</td>\n",
       "      <td>0.271879</td>\n",
       "      <td>-0.039667</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.137953</td>\n",
       "      <td>-1.099149</td>\n",
       "      <td>-1.205795</td>\n",
       "      <td>-0.401901</td>\n",
       "      <td>2.094101</td>\n",
       "      <td>0.697165</td>\n",
       "      <td>...</td>\n",
       "      <td>1.193421</td>\n",
       "      <td>-2.735373</td>\n",
       "      <td>0.940361</td>\n",
       "      <td>-4.081068</td>\n",
       "      <td>1.759097</td>\n",
       "      <td>-2.717352</td>\n",
       "      <td>1.576622</td>\n",
       "      <td>-2.414959</td>\n",
       "      <td>532070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532071</th>\n",
       "      <td>87</td>\n",
       "      <td>7.002739</td>\n",
       "      <td>-0.005065</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.653419</td>\n",
       "      <td>1.294904</td>\n",
       "      <td>0.405524</td>\n",
       "      <td>1.048848</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.144605</td>\n",
       "      <td>1.898965</td>\n",
       "      <td>-1.084516</td>\n",
       "      <td>1.987009</td>\n",
       "      <td>-1.718251</td>\n",
       "      <td>1.591238</td>\n",
       "      <td>-1.292307</td>\n",
       "      <td>1.942232</td>\n",
       "      <td>532071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532072</th>\n",
       "      <td>87</td>\n",
       "      <td>0.171424</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.172026</td>\n",
       "      <td>-3.093182</td>\n",
       "      <td>-1.356817</td>\n",
       "      <td>-1.252079</td>\n",
       "      <td>4.313544</td>\n",
       "      <td>4.437772</td>\n",
       "      <td>...</td>\n",
       "      <td>1.476225</td>\n",
       "      <td>2.239128</td>\n",
       "      <td>1.025673</td>\n",
       "      <td>2.485322</td>\n",
       "      <td>1.700121</td>\n",
       "      <td>2.175138</td>\n",
       "      <td>2.038591</td>\n",
       "      <td>2.655379</td>\n",
       "      <td>532072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532073</th>\n",
       "      <td>87</td>\n",
       "      <td>4.019514</td>\n",
       "      <td>-0.005318</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.659606</td>\n",
       "      <td>-0.386442</td>\n",
       "      <td>0.426953</td>\n",
       "      <td>1.098562</td>\n",
       "      <td>0.019159</td>\n",
       "      <td>0.099820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669236</td>\n",
       "      <td>3.561805</td>\n",
       "      <td>-1.076729</td>\n",
       "      <td>2.028143</td>\n",
       "      <td>-1.661257</td>\n",
       "      <td>1.724619</td>\n",
       "      <td>-1.105069</td>\n",
       "      <td>2.446877</td>\n",
       "      <td>532073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532074</th>\n",
       "      <td>87</td>\n",
       "      <td>0.598352</td>\n",
       "      <td>-0.016445</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.787562</td>\n",
       "      <td>-0.277811</td>\n",
       "      <td>-2.767844</td>\n",
       "      <td>-3.852492</td>\n",
       "      <td>3.324745</td>\n",
       "      <td>4.690789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173087</td>\n",
       "      <td>1.673256</td>\n",
       "      <td>0.360858</td>\n",
       "      <td>3.211130</td>\n",
       "      <td>0.308219</td>\n",
       "      <td>2.072384</td>\n",
       "      <td>0.192604</td>\n",
       "      <td>1.636265</td>\n",
       "      <td>532074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390486</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015396</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.649365</td>\n",
       "      <td>-1.169996</td>\n",
       "      <td>-0.889129</td>\n",
       "      <td>-1.256179</td>\n",
       "      <td>-0.265419</td>\n",
       "      <td>-0.383478</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.260055</td>\n",
       "      <td>1.947725</td>\n",
       "      <td>-1.994399</td>\n",
       "      <td>-1.685163</td>\n",
       "      <td>-2.866165</td>\n",
       "      <td>-0.216130</td>\n",
       "      <td>-1.892048</td>\n",
       "      <td>0.901585</td>\n",
       "      <td>2390486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390487</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004718</td>\n",
       "      <td>1</td>\n",
       "      <td>2.432943</td>\n",
       "      <td>5.284504</td>\n",
       "      <td>-0.337469</td>\n",
       "      <td>-0.494263</td>\n",
       "      <td>-0.442409</td>\n",
       "      <td>-0.739016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.064936</td>\n",
       "      <td>3.119762</td>\n",
       "      <td>-0.419796</td>\n",
       "      <td>-0.208975</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>0.730166</td>\n",
       "      <td>0.648452</td>\n",
       "      <td>2.068737</td>\n",
       "      <td>2390487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390488</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.622475</td>\n",
       "      <td>-0.963682</td>\n",
       "      <td>0.532835</td>\n",
       "      <td>0.392287</td>\n",
       "      <td>0.977046</td>\n",
       "      <td>0.819693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640334</td>\n",
       "      <td>-2.279663</td>\n",
       "      <td>-0.950259</td>\n",
       "      <td>-4.388417</td>\n",
       "      <td>-1.669922</td>\n",
       "      <td>-3.288939</td>\n",
       "      <td>-1.336142</td>\n",
       "      <td>-2.814239</td>\n",
       "      <td>2390488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390489</th>\n",
       "      <td>499</td>\n",
       "      <td>0.283405</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.463757</td>\n",
       "      <td>-1.107228</td>\n",
       "      <td>-2.286985</td>\n",
       "      <td>-3.156451</td>\n",
       "      <td>-1.690676</td>\n",
       "      <td>-2.348199</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.780962</td>\n",
       "      <td>0.881246</td>\n",
       "      <td>-2.202140</td>\n",
       "      <td>-1.912601</td>\n",
       "      <td>-3.341684</td>\n",
       "      <td>-0.571188</td>\n",
       "      <td>-2.185795</td>\n",
       "      <td>0.627452</td>\n",
       "      <td>2390489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390490</th>\n",
       "      <td>499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.817184</td>\n",
       "      <td>-1.131577</td>\n",
       "      <td>0.541893</td>\n",
       "      <td>0.998988</td>\n",
       "      <td>0.412844</td>\n",
       "      <td>0.798855</td>\n",
       "      <td>...</td>\n",
       "      <td>2.483421</td>\n",
       "      <td>8.284037</td>\n",
       "      <td>-0.698486</td>\n",
       "      <td>0.199953</td>\n",
       "      <td>-0.168395</td>\n",
       "      <td>2.051091</td>\n",
       "      <td>1.726072</td>\n",
       "      <td>5.823676</td>\n",
       "      <td>2390490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1858421 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    weight      resp  feature_0  feature_1  feature_2  feature_3  \\\n",
       "532070     87  0.271879 -0.039667         -1   1.137953  -1.099149  -1.205795   \n",
       "532071     87  7.002739 -0.005065         -1  -0.653419   1.294904   0.405524   \n",
       "532072     87  0.171424  0.007406          1  -3.172026  -3.093182  -1.356817   \n",
       "532073     87  4.019514 -0.005318         -1  -1.659606  -0.386442   0.426953   \n",
       "532074     87  0.598352 -0.016445         -1  -0.787562  -0.277811  -2.767844   \n",
       "...       ...       ...       ...        ...        ...        ...        ...   \n",
       "2390486   499  0.000000  0.015396          1  -1.649365  -1.169996  -0.889129   \n",
       "2390487   499  0.000000 -0.004718          1   2.432943   5.284504  -0.337469   \n",
       "2390488   499  0.000000  0.016591          1  -0.622475  -0.963682   0.532835   \n",
       "2390489   499  0.283405 -0.002004         -1  -1.463757  -1.107228  -2.286985   \n",
       "2390490   499  0.000000 -0.001905         -1  -1.817184  -1.131577   0.541893   \n",
       "\n",
       "         feature_4  feature_5  feature_6  ...  feature_122  feature_123  \\\n",
       "532070   -0.401901   2.094101   0.697165  ...     1.193421    -2.735373   \n",
       "532071    1.048848   0.005951   0.066053  ...    -1.144605     1.898965   \n",
       "532072   -1.252079   4.313544   4.437772  ...     1.476225     2.239128   \n",
       "532073    1.098562   0.019159   0.099820  ...    -0.669236     3.561805   \n",
       "532074   -3.852492   3.324745   4.690789  ...     0.173087     1.673256   \n",
       "...            ...        ...        ...  ...          ...          ...   \n",
       "2390486  -1.256179  -0.265419  -0.383478  ...    -1.260055     1.947725   \n",
       "2390487  -0.494263  -0.442409  -0.739016  ...     1.064936     3.119762   \n",
       "2390488   0.392287   0.977046   0.819693  ...    -0.640334    -2.279663   \n",
       "2390489  -3.156451  -1.690676  -2.348199  ...    -1.780962     0.881246   \n",
       "2390490   0.998988   0.412844   0.798855  ...     2.483421     8.284037   \n",
       "\n",
       "         feature_124  feature_125  feature_126  feature_127  feature_128  \\\n",
       "532070      0.940361    -4.081068     1.759097    -2.717352     1.576622   \n",
       "532071     -1.084516     1.987009    -1.718251     1.591238    -1.292307   \n",
       "532072      1.025673     2.485322     1.700121     2.175138     2.038591   \n",
       "532073     -1.076729     2.028143    -1.661257     1.724619    -1.105069   \n",
       "532074      0.360858     3.211130     0.308219     2.072384     0.192604   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "2390486    -1.994399    -1.685163    -2.866165    -0.216130    -1.892048   \n",
       "2390487    -0.419796    -0.208975    -0.146749     0.730166     0.648452   \n",
       "2390488    -0.950259    -4.388417    -1.669922    -3.288939    -1.336142   \n",
       "2390489    -2.202140    -1.912601    -3.341684    -0.571188    -2.185795   \n",
       "2390490    -0.698486     0.199953    -0.168395     2.051091     1.726072   \n",
       "\n",
       "         feature_129    ts_id  y  \n",
       "532070     -2.414959   532070  0  \n",
       "532071      1.942232   532071  0  \n",
       "532072      2.655379   532072  1  \n",
       "532073      2.446877   532073  0  \n",
       "532074      1.636265   532074  0  \n",
       "...              ...      ... ..  \n",
       "2390486     0.901585  2390486  1  \n",
       "2390487     2.068737  2390487  0  \n",
       "2390488    -2.814239  2390488  1  \n",
       "2390489     0.627452  2390489  0  \n",
       "2390490     5.823676  2390490  0  \n",
       "\n",
       "[1858421 rows x 135 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.value_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train/test!\n",
    "\n",
    "train_set, test_set = train_test_split(test_share = 0.9, data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 192.8292236328125 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe after reduction 49.27070236206055 MB\n",
      "Reduced by 74.44852941176471 % \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train_set = reduce_memory_usage(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185842, 135)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(['date','weight','y','ts_id', 'resp'], axis = 1)\n",
    "X_test = test_set.drop(['date','weight','y','ts_id', 'resp'], axis = 1)\n",
    "\n",
    "y_train = train_set.y\n",
    "y_test = test_set.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "       importance_type='gain', interaction_constraints=None,\n",
       "       learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "       n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "       validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc = roc_auc_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_roc = roc_auc_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc: 0.6514900351256979, test roc: 0.5187198773140467\n"
     ]
    }
   ],
   "source": [
    "print(\"Train roc: {}, test roc: {}\".format(train_roc, test_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  del sys.path[0]\n",
      "C:\\Users\\mathias.buxhoeveden\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "(X_train_pca, X_test_pca) = perform_pca_transformation(X_train, X_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "       importance_type='gain', interaction_constraints=None,\n",
       "       learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "       n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "       validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict_proba(X_train_pca)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict_proba(X_test_pca)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_roc = roc_auc_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_roc = roc_auc_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train roc is: 0.6520538782115943, the test roc is: 0.5088760029429306\n"
     ]
    }
   ],
   "source": [
    "print(\"The train roc is: {}, the test roc is: {}\".format(train_roc, test_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "       importance_type='gain', interaction_constraints=None,\n",
       "       learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "       n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "       validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc = roc_auc_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_roc = roc_auc_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train roc is: 0.513151927437448, the test roc is: 0.513748571503123\n"
     ]
    }
   ],
   "source": [
    "print(\"The train roc is: {}, the test roc is: {}\".format(train_roc, test_roc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
